{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"NB06\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLDatasets\n",
    "using Plots, LinearAlgebra, StatsBase, Distributions\n",
    "using Images, ImageCore\n",
    "import Base.Iterators: product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Warning:* For this notebook I had to pin `CSV.jl` to version 0.8.5, because otherwise `MLDatasets` would not compile. This restricts `MLDatasets` to version 0.5. The latest version has a different syntax than the one used here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis\n",
    "\n",
    "In this notebook we will apply PCA to three datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Points on a circle\n",
    "\n",
    "\n",
    "The first dataset is synthetic data generated from the unit circle $S^1 \\subset \\mathbb R^2$.\n",
    "\n",
    "We want to use PCA to learn the geometry of the data.\n",
    "\n",
    "Let us first generate $n=100$ random points on $S^1$ and add Gaussian noise with variance $\\sigma^2 = 0.01$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "σ² = 0.01\n",
    "X = [[cos(ϕ); sin(ϕ)] + sqrt(σ²) .* randn(2) for ϕ in rand(0:0.1:2π, n)];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We center the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x̄ = mean(X);\n",
    "X = map(x -> x - x̄, X);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mat = hcat(X...);\n",
    "scatter(X_mat[1,:], X_mat[2,:], \n",
    "        color = :steelblue, size = (750,250), aspect_ratio = :equal, legend = false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We suspect that there is a polynomial of degree 2 vanishing on the data set.\n",
    "\n",
    "To detect this using PCA we introduce the feature map $\\phi :\\mathbb R^2 \\to \\mathbb R^6$ that sends $x$ to all monomials of degree at most 2 in $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ϕ(x) = [1; x[1]; x[2]; x[1]*x[2]; x[1]^2; x[2]^2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponding feature matrix is $\\Omega$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ω = hcat(map(ϕ, X)...) |> transpose;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compute a singular value decomposition of $\\Omega$.\n",
    "\n",
    "We extract the singular values in the array `svals`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = svd(Ω)\n",
    "svals = S.S;|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normalized differences of the entries of `svals` are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff(svals) ./ svals[2:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that there is significant gap when passing from the 5th to the 6th singular value.\n",
    "\n",
    "Let us check the singular vector corresponding to the 6th singular value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = S.V[:, 6] \n",
    "f = round.(u ./ u[end], digits = 3)\n",
    "println(\"$(f[1]) + $(f[2]) x₁ + $(f[3]) x₂ + $(f[4]) x₁x₂ + $(f[5]) x₁²+ $(f[6]) x₂²\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is close to the actual equation $-1 + x_1^2 + x_2^2 = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometry of Images\n",
    "\n",
    "Let us next consider data from the [CIFAR10](http://www.cs.toronto.edu/~kriz/cifar.html) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X, data_Y = CIFAR10.traindata();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains images of 10 classes of objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"airplane\", \n",
    "          \"automobile\", \n",
    "          \"bird\", \n",
    "          \"cat\", \n",
    "          \"deer\", \n",
    "          \"dog\", \n",
    "          \"frog\", \n",
    "          \"horse\", \n",
    "          \"ship\", \n",
    "          \"truck\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take the subsset consisting of images of trucks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = findfirst(labels .== \"truck\") - 1\n",
    "trucks = data_X[:,:,:, data_Y .== idx];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 5000 images of trucks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = size(trucks, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image consists of $D=32 \\cdot 32 \\cdot 3 = 3072$ numerical values. \n",
    "\n",
    "They represent the RGB values of $32\\times 32$ pixels.\n",
    "\n",
    "Thus, we have data in $\\mathbb R^D$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 32 * 32 * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider a subset $X$ of 500 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500\n",
    "subsample = sample(1:n_images, n, replace = false)\n",
    "\n",
    "X = map(subsample) do i\n",
    "    xᵢ = vec(trucks[:,:,:,i])\n",
    "    Float64.(xᵢ)\n",
    "    end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x̄ = mean(X);\n",
    "stds = std(X);\n",
    "X = map(x -> (x - x̄) ./ stds, X);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take a look at a random subset of 6 images from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = rand(subsample, 6)\n",
    "[CIFAR10.convert2image(trucks[:,:,:,i]) for i in k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to see if there could be a polynomial equation of degree $k=4$ vanishing on the data.\n",
    "\n",
    "For this, we define the kernel map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "κ(x₁, x₂) = (x₁ ⋅ x₂ + 1)^k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute the matrix $R:=W^TW$ from the lecture notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = ones(n);\n",
    "P = diagm(e) - (1/n) .* (e*e');\n",
    "G = [κ(x₁, x₂) for (x₁, x₂) in product(X,X)]\n",
    "\n",
    "R = P * G * P;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the eigenvalues of $R$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = eigen(R);\n",
    "evals = E.values;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and plot their normalized differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot1 = plot(diff(evals) ./ evals[2:end], legend = false, size = (800,250), linewidth = 2.5, linestyle = :dash)\n",
    "scatter!(diff(evals) ./ evals[2:end], \n",
    "        markercolor = :indianred, markerstrokecolor = :indianred, markersize = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eigenvalues are increasing from left to right. \n",
    "\n",
    "We know that $R$ always has a kernel. This is the leftmost point on top.\n",
    "\n",
    "In addition, we see more points on the left separating from the rest. \n",
    "\n",
    "This is an indicator that there could be indeed polynomial equations (approximately) vanishing on the data.\n",
    "\n",
    "For instance, the trucks are photographed from different angles, so that the equation could describe rotational symmetry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Models\n",
    "\n",
    "We consider again the [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist) dataset from [Zalando Research](https://github.com/zalandoresearch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X, data_Y = FashionMNIST.traindata();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"T-shirt/top\", \n",
    "            \"Trouser\", \n",
    "            \"Pullover\", \n",
    "            \"Dress\", \n",
    "            \"Coat\", \n",
    "            \"Sandal\", \n",
    "            \"Shirt\", \n",
    "            \"Sneaker\", \n",
    "            \"Bag\", \n",
    "            \"Ankle boot\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider the subset of the data consisting of images of sneakers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = findfirst(labels .== \"Sneaker\") - 1\n",
    "sneakers = data_X[:,:, data_Y .== idx];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains 6000 images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = size(sneakers, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a subset of $n=500$ images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500\n",
    "subsample = sample(1:n_images, n, replace = false);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take a look at 6 randomly chosen images from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = rand(subsample, 6)\n",
    "[FashionMNIST.convert2image(sneakers[:,:,i]) for i in k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We embed the data in $\\mathbb R^D$ ($D= 28^2 = 784$ for $28\\times 28$ pixels) and center the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 28^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = map(subsample) do i\n",
    "    xᵢ = vec(sneakers[:,:,i])\n",
    "    Float64.(xᵢ)\n",
    "    end;\n",
    "\n",
    "x̄ = mean(X);\n",
    "X = map(x -> x .- x̄, X);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature matrix $\\Omega$ in this case is simply the matrix having the data as rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ω = hcat(X...) |> transpose;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compute a singular value decomposition of $\\Omega$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = svd(Ω)\n",
    "svals = S.S;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot the logarithms of the values in `svals`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "histogram(log.(svals), color = :steelblue, nbins = 100, size = (800,250), \n",
    "                     xticks = -14:2:10, xlims = (-14,10),\n",
    "                     label = \"logarithms of singular values of Ω\", legend = (0.2,0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the majority of singular values is below $\\exp(2)$.\n",
    "\n",
    "Let us choose the linear subspace that is spanned by all eigenvectors for eigenvalues $\\lambda \\geq \\exp(x)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "λ = exp(2)\n",
    "d = findfirst(svals .< λ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aim to approximate the data by a model $x = A\\zeta + b + \\epsilon$ of dimension, where $A\\in\\mathbb R^{D\\times d}$ and\n",
    "\n",
    "$$\\epsilon \\sim N(0,\\sigma^2\\mathbf{1}_D) \\text{ and } \\zeta \\sim N(\\nu, B)$$\n",
    "\n",
    "If $\\Omega = UDV^T$ we take $A$ to be the first $d$ columns of $V$ and $d=\\bar{x}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = S.V[:, 1:d];\n",
    "b = x̄;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also take $\\sigma^2 = 0.001$, $\\nu = 0$ and $C=2\\mathbf 1_d$. \n",
    "\n",
    "This choice seems to work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "σ² = 0.001\n",
    "ν = zeros(d)\n",
    "B = diagm(2 .* ones(d));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We use the [Distributions.jl](https://juliastats.org/Distributions.jl/stable/) package to generate the distributions for $\\epsilon$ and $\\zeta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ζ = MvNormal(ν, B);\n",
    "N_ϵ = MvNormal(zeros(D), diagm(σ² .* ones(D)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now use our model to generate synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ζ = rand(N_ζ, 8)\n",
    "ϵ = rand(N_ϵ, 8)\n",
    "synthetic_data =[A * ζ[:,i] + b + ϵ[:,i] for i in 1:8];\n",
    "synthetic_images = [reshape(u, 28, 28) for u in synthetic_data];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The array `synthetic_images` now contains 8 randomly chosen points from our model.\n",
    "\n",
    "Let us display the corresponding pictures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_image(img) = [Gray(img[i,j]) for (i,j) in product(1:28, 1:28)]'\n",
    "map(create_image, synthetic_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use the distribution $N(\\nu,B)$ as a prior to compute the distribution of $(\\zeta \\mid x)$, where $x$ is an additional data point outside of our subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsample = setdiff(1:n_images, subsample);\n",
    "j = rand(testsample);\n",
    "x =  Float64.(vec(sneakers[:,:,j]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the image corresponding to `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FashionMNIST.convert2image(sneakers[:,:,j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the formula for the posterior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B⁻¹ = inv(B)\n",
    "C = inv((1/σ²) .* diagm(ones(d)) + B⁻¹)\n",
    "m = C * ((1/σ²) .* A' * (x - b) + B⁻¹ * ν);\n",
    "N_ζ_posterior = MvNormal(m, C);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and use the posterior distribution for generating synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ζ = rand(N_ζ_posterior, 4)\n",
    "ϵ = rand(N_ϵ, 4)\n",
    "synthetic_data_2 =[A * ζ[:,i] + b + ϵ[:,i] for i in 1:4]\n",
    "synthetic_images_2 = [reshape(u, 28, 28) for u in synthetic_data_2];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is again the original image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FashionMNIST.convert2image(sneakers[:,:,j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the newly generated images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map(create_image, synthetic_images_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
